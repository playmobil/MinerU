# MinerU VLM é›†æˆæ–‡æ¡£

ğŸš€ **MinerU Pipeline + VLM æ··åˆå¢å¼ºè¡¨æ ¼è¯†åˆ«ç³»ç»Ÿ**

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨ MinerU ä¸­ä½¿ç”¨ VLMï¼ˆVision Language Modelï¼‰å¢å¼ºåŠŸèƒ½ï¼Œç‰¹åˆ«é’ˆå¯¹ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è¿›è¡Œäº†ä¼˜åŒ–ã€‚

## ğŸ“– ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å®‰è£…é…ç½®](#å®‰è£…é…ç½®)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](#ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [API å‚è€ƒ](#api-å‚è€ƒ)

## ğŸ“‹ æ¦‚è¿°

MinerU VLM é›†æˆé‡‡ç”¨**æ™ºèƒ½æ··åˆæ¶æ„**ï¼Œç»“åˆ MinerU Pipeline çš„é«˜æ€§èƒ½ä¸“ä¸šå¤„ç†å’Œ VLM çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼š

- **Pipeline åŸºç¡€å¤„ç†**: ä¿æŒ MinerU åŸæœ‰çš„é«˜é€Ÿã€ä¸“ä¸šåŒ–æ–‡æ¡£è§£æ
- **VLM æ™ºèƒ½å¢å¼º**: ä½¿ç”¨ Table Transformer ç­‰æ¨¡å‹å¢å¼ºè¡¨æ ¼ç»“æ„è¯†åˆ«
- **æ— ç¼é›†æˆ**: é€šè¿‡ç®€å•çš„ `--vlm` å‚æ•°å¯ç”¨ï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰å·¥ä½œæµ

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ æ™ºèƒ½å¢å¼º
- **Table Transformer æ”¯æŒ**: Microsoft ä¸“ä¸šè¡¨æ ¼è¯†åˆ«æ¨¡å‹
- **è‡ªé€‚åº”å¤„ç†**: æ ¹æ®è¡¨æ ¼å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥
- **è¯­ä¹‰ç†è§£**: æå‡å¤æ‚è¡¨æ ¼çš„ç»“æ„è¯†åˆ«å‡†ç¡®æ€§

### âš¡ æ€§èƒ½ä¼˜åŒ–
- **A100/V100 ä¸“é—¨ä¼˜åŒ–**: æ£€æµ‹é«˜ç«¯ GPU å¹¶è‡ªåŠ¨ä¼˜åŒ–é…ç½®
- **Flash Attention 2**: A100 ç¯å¢ƒä¸‹è‡ªåŠ¨å¯ç”¨
- **æ··åˆç²¾åº¦**: FP16 ä¼˜åŒ–ï¼Œå‡å°‘ 50% æ˜¾å­˜å ç”¨
- **æ‰¹å¤„ç†ä¼˜åŒ–**: æ™ºèƒ½æ‰¹å¤„ç†å¤§å°è°ƒæ•´

### ğŸ›¡ï¸ ç”Ÿäº§å°±ç»ª
- **ä¼˜é›…é™çº§**: VLM ä¸å¯ç”¨æ—¶è‡ªåŠ¨å›é€€åˆ° Pipeline æ¨¡å¼
- **å†…å­˜ç®¡ç†**: ä½å†…å­˜å ç”¨å’Œå†…å­˜ä¼˜åŒ–æ¨¡å¼
- **è®¾å¤‡è‡ªé€‚åº”**: è‡ªåŠ¨æ£€æµ‹å¹¶é€‚é…ä¸åŒç¡¬ä»¶ç¯å¢ƒ
- **æ—¥å¿—ç›‘æ§**: è¯¦ç»†çš„å¤„ç†è¿‡ç¨‹æ—¥å¿—

## ğŸ’» ç³»ç»Ÿè¦æ±‚

### åŸºç¡€è¦æ±‚
- **Python**: 3.8+
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 18.04+), macOS, Windows
- **å†…å­˜**: æœ€ä½ 8GB RAMï¼Œæ¨è 16GB+

### GPU è¦æ±‚
- **NVIDIA GPU**: æ”¯æŒ CUDA 11.0+
- **æ˜¾å­˜**: æœ€ä½ 6GBï¼Œæ¨è 8GB+
- **ä¼˜åŒ–æ”¯æŒ**: A100, V100, H100, A6000

### è½¯ä»¶ä¾èµ–
```bash
# å¿…éœ€ä¾èµ–
torch>=2.0.0
torchvision>=0.15.0
transformers>=4.35.0
timm>=0.9.0

# å¯é€‰ä¼˜åŒ–ä¾èµ–
flash-attn>=2.0.0        # A100 Flash Attention 2
xformers>=0.0.20         # å†…å­˜ä¼˜åŒ–
bitsandbytes>=0.41.0     # é‡åŒ–æ”¯æŒ
```

## ğŸ”§ å®‰è£…é…ç½®

### 1. ç¯å¢ƒå‡†å¤‡

#### Linux/Ubuntuï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt-get update && sudo apt-get upgrade -y

# å®‰è£…ç³»ç»Ÿä¾èµ–
sudo apt-get install -y python3 python3-pip python3-venv \
    git wget curl build-essential \
    libgl1-mesa-glx libglib2.0-0 libgomp1

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv_mineru_vlm
source venv_mineru_vlm/bin/activate
```

#### macOS
```bash
# ä½¿ç”¨ Homebrew å®‰è£…ä¾èµ–
brew install python git

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv_mineru_vlm
source venv_mineru_vlm/bin/activate
```

### 2. å®‰è£…æ ¸å¿ƒä¾èµ–

```bash
# å‡çº§ pip
pip install --upgrade pip

# å®‰è£… PyTorch (é€‰æ‹©é€‚åˆçš„ç‰ˆæœ¬)
# CUDA ç‰ˆæœ¬ (Linux/Windows)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# MPS ç‰ˆæœ¬ (Apple Silicon Mac)
pip install torch torchvision torchaudio

# CPU ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 3. å®‰è£… VLM ä¾èµ–

```bash
# Transformers ç”Ÿæ€
pip install transformers>=4.35.0
pip install accelerate>=0.20.0
pip install sentencepiece protobuf

# Table Transformer æ”¯æŒ
pip install timm

# ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
pip install flash-attn xformers bitsandbytes optimum
```

### 4. å®‰è£… MinerU

```bash
# ä»æºç å®‰è£…æœ€æ–°ç‰ˆæœ¬
git clone https://github.com/opendatalab/MinerU.git
cd MinerU
pip install -e .

# æˆ–è€…ä½¿ç”¨åŒ…ç®¡ç†å™¨
pip install -U magic-pdf[full] --extra-index-url https://wheels.myhloli.com
```

### 5. éªŒè¯å®‰è£…

```bash
python -c "
import torch
import transformers
import timm
from mineru.backend.pipeline.model_init import VLM_AVAILABLE

print(f'PyTorch: {torch.__version__}')
print(f'CUDA Available: {torch.cuda.is_available()}')
print(f'Transformers: {transformers.__version__}')
print(f'TIMM: {timm.__version__}')
print(f'VLM Available: {VLM_AVAILABLE}')

if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory // 1024**3}GB')
"
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºç¡€ä½¿ç”¨

```bash
# ä¸å¯ç”¨ VLMï¼ˆé»˜è®¤ Pipeline æ¨¡å¼ï¼‰
mineru -p document.pdf -o output/

# å¯ç”¨ VLM å¢å¼º
mineru -p document.pdf -o output/ --vlm

# å®Œæ•´å‚æ•°ç¤ºä¾‹
mineru -p document.pdf -o output/ \
    --vlm \
    -d cuda:0 \
    -l ch \
    -m auto \
    --vram 16
```

### Python API ä½¿ç”¨

```python
from mineru.cli.common import do_parse
from pathlib import Path

# è¯»å–æ–‡æ¡£
pdf_path = "document.pdf"
with open(pdf_path, 'rb') as f:
    pdf_bytes = f.read()

# VLM å¢å¼ºå¤„ç†
result = do_parse(
    output_dir="output/",
    pdf_file_names=["document"],
    pdf_bytes_list=[pdf_bytes],
    p_lang_list=["ch"],
    backend="pipeline",
    parse_method="auto",
    formula_enable=True,
    table_enable=True,
    enable_vlm=True,  # å¯ç”¨ VLM
    device_mode="cuda:0"
)
```

### é«˜çº§é…ç½®

```python
# è‡ªå®šä¹‰ VLM å¤„ç†å™¨
from mineru.backend.pipeline.model_init import TableVLMProcessor

# ä½¿ç”¨ä¸åŒçš„ VLM æ¨¡å‹
vlm_processor = TableVLMProcessor(
    model_name="microsoft/table-transformer-structure-recognition",
    device="cuda:0"
)

# æ‰‹åŠ¨å¤„ç†è¡¨æ ¼å›¾åƒ
from PIL import Image
image = Image.open("table.png")
result = vlm_processor.enhance_table_result(
    image=image,
    table_result={"html": "<table>...</table>"},
    context="financial report analysis"
)
```

## ğŸ­ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

æˆ‘ä»¬æä¾›äº†å®Œæ•´çš„ Ubuntu A100 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è„šæœ¬ï¼š

```bash
# ä¸‹è½½éƒ¨ç½²è„šæœ¬
wget https://raw.githubusercontent.com/your-repo/MinerU/main/deploy_production_ubuntu_a100.sh

# æ‰§è¡Œéƒ¨ç½²
chmod +x deploy_production_ubuntu_a100.sh
sudo ./deploy_production_ubuntu_a100.sh
```

### æ‰‹åŠ¨éƒ¨ç½²æ­¥éª¤

#### 1. ç¯å¢ƒæ£€æŸ¥

```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ CUDA
nvcc --version

# æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
lsb_release -a
uname -a
```

#### 2. åˆ›å»ºç”Ÿäº§ç¯å¢ƒ

```bash
# åˆ›å»ºä¸“ç”¨ç”¨æˆ·ï¼ˆæ¨èï¼‰
sudo useradd -m -s /bin/bash mineru
sudo usermod -aG sudo mineru
sudo su - mineru

# è®¾ç½®å·¥ä½œç›®å½•
mkdir -p /opt/mineru
cd /opt/mineru

# å…‹éš†ä»£ç 
git clone https://github.com/opendatalab/MinerU.git
cd MinerU
```

#### 3. ç¯å¢ƒå˜é‡é…ç½®

```bash
# åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶
cat > ~/.mineru_production << 'EOF'
# MinerU Production Environment
export MINERU_HOME=/opt/mineru/MinerU
export MINERU_VLM_ENABLED=true
export MINERU_DEVICE_MODE=cuda
export MINERU_MIN_BATCH_INFERENCE_SIZE=512

# CUDA ä¼˜åŒ–
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
export TORCH_CUDNN_V8_API_ENABLED=1
export CUDNN_BENCHMARK=1

# ç¼“å­˜ç›®å½•
export TRANSFORMERS_CACHE=/tmp/transformers_cache
export HF_HOME=/tmp/huggingface_cache

# Python Path
export PYTHONPATH=$MINERU_HOME:$PYTHONPATH
export PATH=$MINERU_HOME/venv/bin:$PATH
EOF

# åŠ è½½ç¯å¢ƒå˜é‡
source ~/.mineru_production
```

#### 4. åˆ›å»ºç”Ÿäº§æœåŠ¡

```bash
# åˆ›å»º systemd æœåŠ¡
sudo tee /etc/systemd/system/mineru-vlm.service << EOF
[Unit]
Description=MinerU VLM Processing Service
After=network.target nvidia-persistenced.service

[Service]
Type=forking
User=mineru
Group=mineru
WorkingDirectory=/opt/mineru/MinerU
Environment=PATH=/opt/mineru/MinerU/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
EnvironmentFile=/home/mineru/.mineru_production
ExecStart=/opt/mineru/MinerU/scripts/start_production.sh
ExecStop=/opt/mineru/MinerU/scripts/stop_production.sh
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal
SyslogIdentifier=mineru-vlm

[Install]
WantedBy=multi-user.target
EOF

# å¯ç”¨æœåŠ¡
sudo systemctl daemon-reload
sudo systemctl enable mineru-vlm
sudo systemctl start mineru-vlm
```

### å®¹å™¨åŒ–éƒ¨ç½²

#### Dockerfile ç¤ºä¾‹

```dockerfile
FROM nvidia/cuda:12.1-devel-ubuntu22.04

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_VISIBLE_DEVICES=0

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-venv \
    git wget curl \
    libgl1-mesa-glx libglib2.0-0 \
    libgomp1 build-essential \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºå·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ä»£ç 
COPY . .

# å®‰è£… Python ä¾èµ–
RUN python3 -m venv venv && \
    . venv/bin/activate && \
    pip install --upgrade pip && \
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 && \
    pip install transformers>=4.35.0 accelerate timm && \
    pip install -e .

# è®¾ç½®æƒé™
RUN chmod +x scripts/*.sh

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœæœ‰ API æœåŠ¡ï¼‰
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["./scripts/start_container.sh"]
```

#### Docker Compose é…ç½®

```yaml
version: '3.8'

services:
  mineru-vlm:
    build: .
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - CUDA_VISIBLE_DEVICES=0
      - MINERU_VLM_ENABLED=true
    volumes:
      - ./data:/app/data
      - ./output:/app/output
      - /tmp/model_cache:/tmp/transformers_cache
    ports:
      - "8000:8000"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### ç¡¬ä»¶ä¼˜åŒ–é…ç½®

#### A100/V100 é«˜ç«¯ GPU
```python
# åœ¨ä»£ç ä¸­è‡ªåŠ¨æ£€æµ‹å¹¶åº”ç”¨
# æˆ–æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡
export MINERU_GPU_TYPE=A100
export MINERU_FLASH_ATTENTION=true
export MINERU_FP16=true
export MINERU_BATCH_SIZE=32
```

#### ä¸­ç«¯ GPU (RTX 3080/4080)
```bash
export MINERU_FP16=true
export MINERU_BATCH_SIZE=16
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256
```

#### å…¥é—¨çº§ GPU
```bash
export MINERU_FP16=false
export MINERU_BATCH_SIZE=8
export MINERU_LOW_MEM_MODE=true
```

### è½¯ä»¶ä¼˜åŒ–é…ç½®

#### æ¨¡å‹é€‰æ‹©ä¼˜åŒ–
```python
# æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹
from mineru.backend.pipeline.model_init import get_optimal_table_model_type

# A100 ç¯å¢ƒ - ä¼˜å…ˆç²¾åº¦
model_type = get_optimal_table_model_type(
    device="cuda:0", 
    image_count=100,
    performance_priority="accuracy"
)
# è¿”å›: "unitable"

# æ‰¹é‡å¤„ç† - ä¼˜å…ˆé€Ÿåº¦
model_type = get_optimal_table_model_type(
    device="cuda:0", 
    image_count=1000,
    performance_priority="speed"
)
# è¿”å›: "slanet_plus"
```

#### æ‰¹å¤„ç†ä¼˜åŒ–
```bash
# æ ¹æ®æ˜¾å­˜å¤§å°è®¾ç½®æ‰¹å¤„ç†
# 32GB+ æ˜¾å­˜
export MINERU_MIN_BATCH_INFERENCE_SIZE=1024

# 16-24GB æ˜¾å­˜
export MINERU_MIN_BATCH_INFERENCE_SIZE=512

# 8-12GB æ˜¾å­˜
export MINERU_MIN_BATCH_INFERENCE_SIZE=256
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# è¿è¡ŒåŸºå‡†æµ‹è¯•
python scripts/benchmark_vlm.py \
    --test-dir ./test_data \
    --output-dir ./benchmark_results \
    --gpu-id 0 \
    --vlm-enabled true
```

é¢„æœŸæ€§èƒ½æŒ‡æ ‡ï¼š

| ç¡¬ä»¶é…ç½® | æ¨¡å¼ | å¤„ç†é€Ÿåº¦ | å‡†ç¡®ç‡ | æ˜¾å­˜å ç”¨ |
|---------|------|----------|---------|----------|
| **A100 80GB** | Pipeline + VLM | ~0.5s/é¡µ | 98%+ | ~12GB |
| **V100 32GB** | Pipeline + VLM | ~0.8s/é¡µ | 97%+ | ~10GB |
| **RTX 4080** | Pipeline + VLM | ~1.2s/é¡µ | 96%+ | ~8GB |
| **RTX 3080** | Pipeline Only | ~0.6s/é¡µ | 94%+ | ~6GB |

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. VLM æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# é”™è¯¯ä¿¡æ¯
ERROR: Failed to load VLM model: Insufficient GPU memory

# è§£å†³æ–¹æ¡ˆ
export MINERU_LOW_MEM_MODE=true
export MINERU_VLM_FP16=true
# æˆ–è€…ä½¿ç”¨æ›´å°çš„æ¨¡å‹
export MINERU_VLM_MODEL=microsoft/table-transformer-detection
```

#### 2. CUDA å†…å­˜ä¸è¶³
```bash
# é”™è¯¯ä¿¡æ¯
RuntimeError: CUDA out of memory

# è§£å†³æ–¹æ¡ˆ
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
export MINERU_BATCH_SIZE=4
# æ¸…ç†ç¼“å­˜
python -c "import torch; torch.cuda.empty_cache()"
```

#### 3. Table Transformer ä¾èµ–é—®é¢˜
```bash
# é”™è¯¯ä¿¡æ¯
ImportError: timm not found

# è§£å†³æ–¹æ¡ˆ
pip install timm>=0.9.0
# é‡å¯ Python ç¯å¢ƒ
```

#### 4. æ€§èƒ½é—®é¢˜è¯Šæ–­
```python
# æ€§èƒ½åˆ†æè„šæœ¬
import time
import torch
from mineru.backend.pipeline.model_init import TableVLMProcessor

# æµ‹è¯• VLM åŠ è½½æ—¶é—´
start = time.time()
processor = TableVLMProcessor(device="cuda:0")
load_time = time.time() - start
print(f"VLM load time: {load_time:.2f}s")

# æµ‹è¯• GPU åˆ©ç”¨ç‡
print(f"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f}GB")
print(f"GPU Utilization: {torch.cuda.utilization()}%")
```

### æ—¥å¿—åˆ†æ

#### å¯ç”¨è¯¦ç»†æ—¥å¿—
```bash
export MINERU_LOG_LEVEL=DEBUG
export MINERU_VLM_DEBUG=true

# è¿è¡Œå¹¶æŸ¥çœ‹æ—¥å¿—
mineru -p document.pdf -o output/ --vlm 2>&1 | tee mineru_debug.log
```

#### å…³é”®æ—¥å¿—æŒ‡æ ‡
```bash
# VLM æˆåŠŸå¯ç”¨
grep "VLM enhancement enabled" mineru_debug.log

# æ¨¡å‹åŠ è½½æ—¶é—´
grep "model init cost" mineru_debug.log

# å¤„ç†æ€§èƒ½
grep "Processing pages" mineru_debug.log

# é”™è¯¯è¯Šæ–­
grep -i "error\|warning\|failed" mineru_debug.log
```

## ğŸ“š API å‚è€ƒ

### å‘½ä»¤è¡Œå‚æ•°

```bash
mineru [OPTIONS] -p INPUT -o OUTPUT

Options:
  -p, --path PATH         è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ [å¿…éœ€]
  -o, --output PATH       è¾“å‡ºç›®å½•è·¯å¾„ [å¿…éœ€]
  --vlm, --enable-vlm     å¯ç”¨ VLM å¢å¼º [é»˜è®¤: False]
  -d, --device TEXT       è®¾å¤‡æ¨¡å¼ (cpu/cuda/mps) [é»˜è®¤: auto]
  -l, --lang TEXT         OCR è¯­è¨€ [é»˜è®¤: ch]
  -m, --method TEXT       è§£ææ–¹æ³• (auto/ocr/txt) [é»˜è®¤: auto]
  --vram INTEGER          GPU æ˜¾å­˜é™åˆ¶ (GB)
  -b, --backend TEXT      åç«¯ç±»å‹ [é»˜è®¤: pipeline]
  -f, --formula           å¯ç”¨å…¬å¼è¯†åˆ« [é»˜è®¤: True]
  -t, --table             å¯ç”¨è¡¨æ ¼è¯†åˆ« [é»˜è®¤: True]
  --source TEXT           æ¨¡å‹æº (huggingface/modelscope) [é»˜è®¤: huggingface]
  -v, --version           æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
  --help                  æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
```

### Python API

#### æ ¸å¿ƒå‡½æ•°
```python
from mineru.cli.common import do_parse

def do_parse(
    output_dir: str,
    pdf_file_names: List[str],
    pdf_bytes_list: List[bytes],
    p_lang_list: List[str],
    backend: str = "pipeline",
    parse_method: str = "auto", 
    formula_enable: bool = True,
    table_enable: bool = True,
    enable_vlm: bool = False,  # VLM å¼€å…³
    device_mode: str = None,
    **kwargs
) -> None
```

#### VLM å¤„ç†å™¨ç±»
```python
from mineru.backend.pipeline.model_init import TableVLMProcessor

class TableVLMProcessor:
    def __init__(
        self, 
        model_name: str = "microsoft/table-transformer-structure-recognition",
        device: str = None
    )
    
    def enhance_table_result(
        self, 
        image: PIL.Image,
        table_result: dict,
        context: str = ""
    ) -> dict
```

#### æ¨¡å‹é…ç½®ç±»
```python
from mineru.backend.pipeline.model_init import MineruPipelineModel

class MineruPipelineModel:
    def __init__(
        self,
        device: str = "cpu",
        table_config: dict = None,
        formula_config: dict = None,
        lang: str = None,
        enable_vlm: bool = False,  # VLM é…ç½®
        image_count: int = None,
        performance_priority: str = "balanced"
    )
```

### ç¯å¢ƒå˜é‡

| å˜é‡å | æè¿° | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|--------|------|--------|------|
| `MINERU_DEVICE_MODE` | è®¾å¤‡æ¨¡å¼ | auto | cuda:0 |
| `MINERU_VLM_ENABLED` | VLM å…¨å±€å¼€å…³ | false | true |
| `MINERU_MIN_BATCH_INFERENCE_SIZE` | æ‰¹å¤„ç†å¤§å° | 384 | 512 |
| `MINERU_VIRTUAL_VRAM_SIZE` | è™šæ‹Ÿæ˜¾å­˜é™åˆ¶ | auto | 16 |
| `PYTORCH_CUDA_ALLOC_CONF` | CUDA å†…å­˜é…ç½® | - | max_split_size_mb:512 |
| `TRANSFORMERS_CACHE` | æ¨¡å‹ç¼“å­˜ç›®å½• | ~/.cache | /tmp/transformers_cache |
| `MINERU_MODEL_SOURCE` | æ¨¡å‹æº | huggingface | modelscope |

## ğŸ“ æ”¯æŒä¸è´¡çŒ®

### è·å–å¸®åŠ©
- **GitHub Issues**: [æäº¤é—®é¢˜](https://github.com/opendatalab/MinerU/issues)
- **æ–‡æ¡£**: [å®Œæ•´æ–‡æ¡£](https://github.com/opendatalab/MinerU/wiki)
- **ç¤¾åŒºè®¨è®º**: [Discussions](https://github.com/opendatalab/MinerU/discussions)

### è´¡çŒ®æŒ‡å—
1. Fork é¡¹ç›®ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature-vlm-enhancement`
3. æäº¤æ›´æ”¹: `git commit -am 'Add VLM enhancement'`
4. æ¨é€åˆ†æ”¯: `git push origin feature-vlm-enhancement`
5. åˆ›å»º Pull Request

### ç‰ˆæœ¬å†å²
- **v1.0.0**: VLM é›†æˆåŸºç¡€ç‰ˆæœ¬
- **v1.1.0**: A100 ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–
- **v1.2.0**: å¤šæ¨¡å‹æ”¯æŒå’Œæ€§èƒ½ä¼˜åŒ–

---

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº Apache 2.0 è®¸å¯è¯å¼€æºã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

**ğŸ‰ æ„Ÿè°¢ä½¿ç”¨ MinerU VLM å¢å¼ºåŠŸèƒ½ï¼**

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç»™æˆ‘ä»¬ä¸€ä¸ª â­ Starï¼